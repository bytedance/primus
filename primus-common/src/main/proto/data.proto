/*
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *    http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

syntax = "proto3";
package primus;

option java_outer_classname = "DataProto";
option java_package = "com.bytedance.primus.apiserver.proto";
option java_generate_equals_and_hash = true;

import "primus_common.proto";

message DataSpec {
  map<string, DataStreamSpec> dataStreamSpecs = 1;
  // states for recovery
  DataSavepoint data_savepoint = 2;
  int32 total_datastream_count = 3;
}

message DataStatus {
  map<string, DataStreamStatus> dataStreamStatuses = 2;
}

message DataStreamSpec {
  repeated DataSourceSpec dataSourceSpecs = 1;
  OperatorPolicy operatorPolicy = 2;
  string workflow_name = 4;
}

message DataStreamStatus {
  enum DataStreamState {
    PENDING = 0;
    RUNNING = 1;
    SUCCEEDED = 2;
    FAILED = 3;
  }

  DataStreamState state = 1;
  float progress = 2;  // 0 ~ 1.0
  repeated DataSourceStatus data_source_statuses = 3;
}

message DataSourceSpec {
  string source_id = 5;  // unique data source id within a data stream
  string source = 1;
  oneof dataSource {
    FileSourceSpec fileSourceSpec = 2;
    // Forward compatibility, may be deprecated in future
    KafkaSourceSpec kafkaSourceSpec = 4;
  }
}

message DataSourceStatus {
  string source_id = 1;  // unique data source id within a data stream
  int32 data_consumption_time = 2;  // format: YYYYMMDDHH
}

message FileSourceSpec {
  enum InputType {
    UNKNOWN_INPUT = 0;
    RAW_INPUT = 1;
    TEXT_INPUT = 2;
  }

  string input = 2;
  InputType inputType = 4;
  string fileNameFilter = 6;

  DayFormat day_format = 20;
  TimeRange time_range = 21;
}

message FileSourceStatus {
}

message KafkaSourceSpec {
  enum KafkaMessageType {
    JSON = 0;
    PB = 1;
  }

  enum KafkaStartUpMode {
    GROUP_OFFSETS = 0;
    EARLIEST = 1;
    LATEST = 2;
    TIMESTAMP = 3;
  }

  message Topic {
    string topic = 2;
    string consumer_group = 3;
    map<string, string> config = 4;
    KafkaStartUpMode kafka_start_up_mode = 5;
    int64 start_up_timestamp = 6;
  }

  Topic topic = 1;
  KafkaMessageType kafka_message_type = 2;
}

message KafkaSourceStatus {
}

message OperatorPolicy {
  enum OperatorType {
    MAP_IDENTITY = 0;
    MAP_DELAY = 1;

    GROUP_BY_KEY = 100;

    MAP_PARTITIONS_IDENTITY = 200;
    MAP_PARTITIONS_SAMPLE = 201;
    MAP_PARTITIONS_SHUFFLE = 202;

    SORT_BY_KEY = 300;
    SHUFFLE_BY_KEY = 301;
  }

  message OperatorConf {
    OperatorType operatorType = 1;
    repeated string arguments = 2;
  }

  message CommonOperatorPolicy {
    OperatorConf map = 1;
    OperatorConf groupByKey = 2;
    OperatorConf mapPartitionsFunction = 3;
    OperatorConf sortByKey = 4;
  }

  oneof operatorPolicy {
    CommonOperatorPolicy commonOperatorPolicy = 1;
  }
}

message DataSavepointSpec {
  string savepoint_dir = 1;
}

message DataSavepointStatus {
  enum DataSavepointState {
    PENDING = 0;
    RUNNING = 1;
    SUCCEEDED = 2;
    FAILED = 3;
  }

  DataSavepointState state = 1;
}

message DataSavepoint {
  string restore_id = 1;
  DataSavepointSpec data_savepoint_spec = 2;
}